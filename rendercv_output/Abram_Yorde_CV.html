<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>
        
    </title>
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.1/github-markdown-light.min.css"
        integrity="sha512-Pmhg2i/F7+5+7SsdoUqKeH7UAZoVMYb1sxGOoJ0jWXAEHP0XV2H4CITyK267eHWp2jpj7rtqWNkmEOw1tNyYpg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.12/dist/katex.min.css" integrity="sha384-PDbUeNCuE6bOPudPOgFyIUEy3UJawJVwr3XlGO90FIuf5qNIoTLSgOJo/dC2ZXV/" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.12/dist/katex.min.js" integrity="sha384-VkqWq8xtm5YQk1BBXczQ8/Sx+DlCzF8cuS43bZwmtVXzRFtyLTqTCdP7MKmKo+KN" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.12/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
        onload="renderMathInElement(document.body, {delimiters: [{ left: '$$',  right: '$$',  display: false }]});"></script>
    <style>
        .markdown-body {
            box-sizing: border-box;
            min-width: 200px;
            max-width: 980px;
            margin: 0 auto;
            padding: 45px;
        }

        @media (max-width: 767px) {
            .markdown-body {
                padding: 15px;
            }
        }
    </style>
</head>

<body>
    <article class="markdown-body">
        <h1>Abram Yorde's CV</h1>
        <ul>
        <li>Phone: +1 937 507 1958</li>
        <li>Email: <a href="mailto:abram.yorde@outlook.com">abram.yorde@outlook.com</a></li>
        <li>Location: Englewood, OH</li>
        <li>LinkedIn: <a href="https://linkedin.com/in/Abram Yorde">Abram Yorde</a></li>
        <li>GitHub: <a href="https://github.com/AbramYorde">AbramYorde</a></li>
        </ul>
        <h1>Objective</h1>
        <p>Enable internal and external customer success via data and analytics solutions and models.</p>
        <p>Ensure these customer’s success and guide them from reactionary to proactive and guided decision making.</p>
        <h1>Education</h1>
        <h2><strong>Georgia Institute of Technology</strong>, Analytics</h2>
        <p><strong>MS</strong></p>
        <p>Atlanta, GA</p>
        <p>Jan 2019 – Dec 2021</p>
        <ul>
        <li>GPA: 3.66 \/ 4.00</li>
        </ul>
        <h2><strong>Wright State University</strong>, Mechanical Engineering</h2>
        <p><strong>BS</strong></p>
        <p>Dayton, OH</p>
        <p>Jan 2015 – Dec 2017</p>
        <ul>
        <li>GPA: 3.71 \/ 4.00</li>
        </ul>
        <h1>Experience</h1>
        <h2><strong>Copeland</strong>, Senior Data Engineer</h2>
        <p>Remote</p>
        <p>Apr 2024 – present</p>
        <p>1 year 9 months</p>
        <ul>
        <li>Lorem Epsum</li>
        </ul>
        <h2><strong>Copeland</strong>, Senior Data Scientist</h2>
        <p>Sidney, OH</p>
        <p>Jan 2023 – Aug 2024</p>
        <p>1 year 8 months</p>
        <ul>
        <li>Lorem Epsum</li>
        </ul>
        <h2><strong>Emerson Climate Technologies</strong>, Data Scientist</h2>
        <p>Sidney, OH</p>
        <p>Jan 2020 – Jan 2023</p>
        <p>3 years 1 month</p>
        <ul>
        <li>Lorem Epsum</li>
        </ul>
        <h2><strong>Emerson Climate Technologies</strong>, Refrigeration Project Engineer - Data Science</h2>
        <p>Sidney, OH</p>
        <p>Jan 2018 – Jan 2020</p>
        <p>2 years 1 month</p>
        <ul>
        <li>
        <p>Created on-device neural network compression pipeline deployed across 50M+ devices</p>
        </li>
        <li>
        <p>Filed 2 patents on efficient model quantization techniques for edge inference</p>
        </li>
        </ul>
        <h2><strong>Emerson Climate Technologies</strong>, Refrigeration Internships (Multiple Departments)</h2>
        <p>Sidney, OH</p>
        <p>Aug 2015 – Jan 2018</p>
        <p>2 years 6 months</p>
        <ul>
        <li>
        <p>Implemented novel self-supervised learning framework for low-resource language modeling</p>
        </li>
        <li>
        <p>Research integrated into Azure Cognitive Services, reducing training data requirements by 60\%</p>
        </li>
        </ul>
        <h1>Projects</h1>
        <h2><strong>#link("https://github.com/")[FlashInfer]</strong></h2>
        <p>Jan 2023 – present</p>
        <h1>summary[Open-source library for high-performance LLM inference kernels]</h1>
        <ul>
        <li>
        <p>Achieved 2.8x speedup over baseline attention implementations on A100 GPUs</p>
        </li>
        <li>
        <p>Adopted by 3 major AI labs, 8,500+ GitHub stars, 200+ contributors</p>
        </li>
        </ul>
        <h2><strong>#link("https://github.com/")[NeuralPrune]</strong></h2>
        <p>Jan 2021</p>
        <h1>summary[Automated neural network pruning toolkit with differentiable masks]</h1>
        <ul>
        <li>
        <p>Reduced model size by 90\% with less than 1\% accuracy degradation on ImageNet</p>
        </li>
        <li>
        <p>Featured in PyTorch ecosystem tools, 4,200+ GitHub stars</p>
        </li>
        </ul>
        <h1>Selected Honors</h1>
        <ul>
        <li>
        <p>MIT Technology Review 35 Under 35 Innovators (2024)</p>
        </li>
        <li>
        <p>Forbes 30 Under 30 in Enterprise Technology (2024)</p>
        </li>
        <li>
        <p>ACM Doctoral Dissertation Award Honorable Mention (2023)</p>
        </li>
        <li>
        <p>Google PhD Fellowship in Machine Learning (2020 – 2023)</p>
        </li>
        <li>
        <p>Fulbright Scholarship for Graduate Studies (2018)</p>
        </li>
        </ul>
        <h1>Skills</h1>
        <ul>
        <li>
        <p>Languages: Python, C++, CUDA, Rust, Julia</p>
        </li>
        <li>
        <p>ML Frameworks: PyTorch, JAX, TensorFlow, Triton, ONNX</p>
        </li>
        <li>
        <p>Infrastructure: Kubernetes, Ray, distributed training, AWS, GCP</p>
        </li>
        <li>
        <p>Research Areas: Neural architecture search, model compression, efficient inference, multi-agent RL</p>
        </li>
        </ul>
        <h1>Patents</h1>
        <ul>
        <li>
        <p>Adaptive Quantization for Neural Network Inference on Edge Devices (US Patent 11,234,567)</p>
        </li>
        <li>
        <p>Dynamic Sparsity Patterns for Efficient Transformer Attention (US Patent 11,345,678)</p>
        </li>
        <li>
        <p>Hardware-Aware Neural Architecture Search Method (US Patent 11,456,789)</p>
        </li>
        </ul>
        <h1>Invited Talks</h1>
        <ul>
        <li>
        <p>Scaling Laws for Efficient Inference — Stanford HAI Symposium (2024)</p>
        </li>
        <li>
        <p>Building AI Infrastructure for the Next Decade — TechCrunch Disrupt (2024)</p>
        </li>
        <li>
        <p>From Research to Production: Lessons in ML Systems — NeurIPS Workshop (2023)</p>
        </li>
        <li>
        <p>Efficient Deep Learning: A Practitioner's Perspective — Google Tech Talk (2022)</p>
        </li>
        </ul>
        <h1>Any Section Title</h1>
        <p>You can use any section title you want.</p>
        <p>You can choose any entry type for the section: <code>TextEntry</code>, <code>ExperienceEntry</code>, <code>EducationEntry</code>, <code>PublicationEntry</code>, <code>BulletEntry</code>, <code>NumberedEntry</code>, or <code>ReversedNumberedEntry</code>.</p>
        <p>Markdown syntax is supported everywhere.</p>
        <p>The <code>design</code> field in YAML gives you control over almost any aspect of your CV design.</p>
        <p>See the #link("https://docs.rendercv.com")[documentation] for more details.</p>
    </article>
</body>

</html>